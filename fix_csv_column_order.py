#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HUGANJOB CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—é †åºä¿®æ­£ãƒ„ãƒ¼ãƒ«
ãƒ‡ãƒ¼ã‚¿ã®é †åºãŒé–“é•ã£ã¦ã„ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£ã—ã„é †åºã«ä¿®æ­£ã—ã¾ã™
"""

import pandas as pd
import csv
import os
from datetime import datetime

def fix_csv_column_order():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—é †åºã‚’ä¿®æ­£"""
    
    print("ğŸ”§ HUGANJOB CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ—é †åºä¿®æ­£ãƒ„ãƒ¼ãƒ«")
    print("="*50)
    
    input_file = 'data/new_input_test.csv'
    backup_file = f'data/new_input_test_backup_column_fix_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
    try:
        import shutil
        shutil.copy2(input_file, backup_file)
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
    except Exception as e:
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ç¾åœ¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    print(f"\nğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {input_file}")
    
    try:
        # æ‰‹å‹•ã§CSVã‚’èª­ã¿è¾¼ã¿ï¼ˆåˆ—ã®é †åºãŒé–“é•ã£ã¦ã„ã‚‹ãŸã‚ï¼‰
        rows = []
        with open(input_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            header = next(reader)
            print(f"ç¾åœ¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼: {header}")
            
            for row in reader:
                if len(row) >= 16:  # æœ€ä½é™ã®åˆ—æ•°ã‚’ç¢ºèª
                    rows.append(row)
        
        print(f"èª­ã¿è¾¼ã¿è¡Œæ•°: {len(rows)}è¡Œ")
        
        # æ­£ã—ã„åˆ—é †åºã§ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹ç¯‰
        print(f"\nğŸ”„ ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä¿®æ­£ä¸­...")
        
        corrected_rows = []
        
        for row in rows:
            # ç¾åœ¨ã®é–“é•ã£ãŸé †åºã‹ã‚‰æ­£ã—ã„é †åºã«ãƒãƒƒãƒ”ãƒ³ã‚°
            # ç¾åœ¨: ID,ä¼æ¥­å(URL),ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸(â€),æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹(è·ç¨®),å‹Ÿé›†è·ç¨®(ç©ºç™½),...
            # æ­£ã—ã„é †åºã«ä¿®æ­£
            
            corrected_row = [
                row[0],  # ID (æ­£ã—ã„)
                '',      # ä¼æ¥­å (å¾Œã§è¨­å®š)
                row[1],  # ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ (ç¾åœ¨ã®ã€Œä¼æ¥­åã€åˆ—ã«URLãŒå…¥ã£ã¦ã„ã‚‹)
                row[2],  # æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ (ç¾åœ¨ã¯ã€Œâ€ã€ãŒå…¥ã£ã¦ã„ã‚‹)
                row[3],  # å‹Ÿé›†è·ç¨® (ç¾åœ¨ã®ã€Œæ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€åˆ—ã«è·ç¨®ãŒå…¥ã£ã¦ã„ã‚‹)
                row[4] if len(row) > 4 else '',   # ãƒã‚¦ãƒ³ã‚¹çŠ¶æ…‹
                row[5] if len(row) > 5 else '',   # ãƒã‚¦ãƒ³ã‚¹æ—¥æ™‚
                row[6] if len(row) > 6 else '',   # ãƒã‚¦ãƒ³ã‚¹ç†ç”±
                row[7] if len(row) > 7 else '',   # é…ä¿¡åœæ­¢çŠ¶æ…‹
                row[8] if len(row) > 8 else '',   # é…ä¿¡åœæ­¢æ—¥æ™‚
                row[9] if len(row) > 9 else '',   # é…ä¿¡åœæ­¢ç†ç”±
                row[11] if len(row) > 11 else '', # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
                row[12] if len(row) > 12 else '', # é€ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
                row[13] if len(row) > 13 else '', # é€ä¿¡æ—¥æ™‚
                row[14] if len(row) > 14 else '', # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                row[15] if len(row) > 15 else ''  # ãƒã‚¦ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—
            ]
            
            # ä¼æ¥­åã‚’URLã‹ã‚‰æ¨å®šï¼ˆç°¡æ˜“çš„ãªå‡¦ç†ï¼‰
            website_url = corrected_row[2]
            if website_url and website_url != 'â€':
                # URLã‹ã‚‰ä¼æ¥­åã‚’æ¨å®šï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³åã‹ã‚‰ï¼‰
                try:
                    from urllib.parse import urlparse
                    domain = urlparse(website_url).netloc
                    if domain:
                        # www. ã‚’é™¤å»
                        domain = domain.replace('www.', '')
                        # .co.jp, .com ãªã©ã‚’é™¤å»ã—ã¦ä¼æ¥­åã®æ¨å®š
                        company_name = domain.split('.')[0]
                        corrected_row[1] = f"ä¼æ¥­å_{company_name}"  # ä»®ã®ä¼æ¥­å
                    else:
                        corrected_row[1] = "ä¼æ¥­åä¸æ˜"
                except:
                    corrected_row[1] = "ä¼æ¥­åä¸æ˜"
            else:
                corrected_row[1] = "ä¼æ¥­åä¸æ˜"
            
            corrected_rows.append(corrected_row)
        
        # æ­£ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š
        correct_header = [
            'ID', 'ä¼æ¥­å', 'ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸', 'æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'å‹Ÿé›†è·ç¨®',
            'ãƒã‚¦ãƒ³ã‚¹çŠ¶æ…‹', 'ãƒã‚¦ãƒ³ã‚¹æ—¥æ™‚', 'ãƒã‚¦ãƒ³ã‚¹ç†ç”±', 'é…ä¿¡åœæ­¢çŠ¶æ…‹', 'é…ä¿¡åœæ­¢æ—¥æ™‚', 'é…ä¿¡åœæ­¢ç†ç”±',
            'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'é€ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'é€ä¿¡æ—¥æ™‚', 'ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸', 'ãƒã‚¦ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—'
        ]
        
        # ä¿®æ­£ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        print(f"ğŸ’¾ ä¿®æ­£ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ä¸­...")
        
        with open(input_file, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(correct_header)
            writer.writerows(corrected_rows)
        
        print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£å®Œäº†: {len(corrected_rows)}è¡Œ")
        print(f"ğŸ“Š æ­£ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼: {correct_header}")
        
        # ä¿®æ­£çµæœã®ç¢ºèª
        print(f"\nğŸ” ä¿®æ­£çµæœç¢ºèª...")
        df_check = pd.read_csv(input_file, encoding='utf-8-sig')
        print(f"âœ… pandasèª­ã¿è¾¼ã¿æˆåŠŸ: {len(df_check)}è¡Œ, {len(df_check.columns)}åˆ—")
        print(f"ğŸ“‹ åˆ—å: {list(df_check.columns)}")
        
        # æœ€åˆã®5è¡Œã‚’è¡¨ç¤º
        print(f"\nğŸ“„ ä¿®æ­£å¾Œã®æœ€åˆã®5è¡Œ:")
        for i in range(min(5, len(df_check))):
            row = df_check.iloc[i]
            print(f"  ID {row['ID']}: {row['ä¼æ¥­å']} | {row['ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸']} | {row['å‹Ÿé›†è·ç¨®']}")
        
        print(f"\nğŸ‰ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—é †åºä¿®æ­£å®Œäº†ï¼")
        print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_file}")
        print(f"ğŸ“ ä¿®æ­£æ¸ˆã¿: {input_file}")
        print(f"ğŸ’¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªã—ã¦ãã ã•ã„: http://127.0.0.1:5002/companies")
        
    except Exception as e:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    fix_csv_column_order()
