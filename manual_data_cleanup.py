#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HUGANJOBæ‰‹å‹•ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
æŒ‡å®šã•ã‚ŒãŸä¼æ¥­IDã‚’å‰Šé™¤ã—ã€IDã‚’æŒ¯ã‚Šç›´ã™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import csv
import json
import os
from datetime import datetime

def main():
    print("ğŸ§¹ HUGANJOBæ‰‹å‹•ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
    print("="*50)
    
    # å‰Šé™¤å¯¾è±¡ä¼æ¥­ID
    target_ids = [2995, 2996, 2997, 4837, 4838, 4839, 4840, 4832, 4833, 4834]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    main_csv = 'data/new_input_test.csv'
    email_results_csv = 'huganjob_email_resolution_results.csv'
    sending_results_csv = 'new_email_sending_results.csv'
    sending_history_json = 'huganjob_sending_history.json'
    
    print(f"ğŸ¯ å‰Šé™¤å¯¾è±¡ä¼æ¥­: {len(target_ids)}ç¤¾")
    print(f"å‰Šé™¤å¯¾è±¡ID: {target_ids}")
    
    # 1. ãƒ¡ã‚¤ãƒ³CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    print(f"\nğŸ“Š ãƒ¡ã‚¤ãƒ³CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {main_csv}")
    
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(main_csv, encoding='utf-8-sig')
        print(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ç¤¾")
        
        # å‰Šé™¤å¯¾è±¡ä¼æ¥­ã®è©³ç´°è¡¨ç¤º
        print(f"\nğŸ—‘ï¸ å‰Šé™¤å¯¾è±¡ä¼æ¥­è©³ç´°:")
        for target_id in target_ids:
            company_row = df[df['ID'] == target_id]
            if not company_row.empty:
                company_name = company_row.iloc[0]['ä¼æ¥­å']
                email = company_row.iloc[0].get('æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'æœªç™»éŒ²')
                print(f"  ID {target_id}: {company_name} ({email})")
            else:
                print(f"  ID {target_id}: ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # å‰Šé™¤å‰ã®ä¼æ¥­æ•°
        before_count = len(df)
        
        # æŒ‡å®šIDã®ä¼æ¥­ã‚’å‰Šé™¤
        df_cleaned = df[~df['ID'].isin(target_ids)].copy()
        
        # å‰Šé™¤å¾Œã®ä¼æ¥­æ•°
        after_count = len(df_cleaned)
        deleted_count = before_count - after_count
        
        print(f"\nâœ… å‰Šé™¤å®Œäº†: {before_count}ç¤¾ â†’ {after_count}ç¤¾ ({deleted_count}ç¤¾å‰Šé™¤)")
        
        # IDã‚’é€£ç•ªã«æŒ¯ã‚Šç›´ã—
        print(f"ğŸ”¢ IDã‚’é€£ç•ªã«æŒ¯ã‚Šç›´ã—ä¸­...")
        df_cleaned['ID'] = range(1, len(df_cleaned) + 1)
        print(f"âœ… IDæŒ¯ã‚Šç›´ã—å®Œäº†: 1 ã€œ {len(df_cleaned)}")
        
        # ä¿å­˜
        df_cleaned.to_csv(main_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… ãƒ¡ã‚¤ãƒ³CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {main_csv}")
        
    except Exception as e:
        print(f"âŒ ãƒ¡ã‚¤ãƒ³CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 2. ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    print(f"\nğŸ“§ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {email_results_csv}")
    
    if os.path.exists(email_results_csv):
        try:
            df_email = pd.read_csv(email_results_csv, encoding='utf-8-sig')
            original_count = len(df_email)
            
            # å‰Šé™¤ã•ã‚ŒãŸIDã‚’é™¤å¤–
            df_email_cleaned = df_email[~df_email['ä¼æ¥­ID'].isin(target_ids)].copy()
            
            # IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆï¼ˆå‰Šé™¤å¾Œã®æ–°ã—ã„IDã«å¯¾å¿œï¼‰
            id_mapping = {}
            current_id = 1
            for _, row in df_cleaned.iterrows():
                old_id = row['ID']  # ã“ã‚Œã¯æ—¢ã«æ–°ã—ã„IDã«ãªã£ã¦ã„ã‚‹
                id_mapping[old_id] = current_id
                current_id += 1
            
            # ä¼æ¥­IDã‚’æ–°ã—ã„å€¤ã«æ›´æ–°ï¼ˆã“ã“ã§ã¯æ—¢ã«é€£ç•ªã«ãªã£ã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨ï¼‰
            # å®Ÿéš›ã«ã¯ã€å…ƒã®IDã¨æ–°ã—ã„IDã®å¯¾å¿œãŒå¿…è¦ã ãŒã€ç°¡å˜ã®ãŸã‚å‰Šé™¤å¾Œã®é€£ç•ªIDã‚’ãã®ã¾ã¾ä½¿ç”¨
            
            df_email_cleaned.to_csv(email_results_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {original_count} â†’ {len(df_email_cleaned)}è¡Œ")
            
        except Exception as e:
            print(f"âŒ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"âš ï¸ {email_results_csv} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 3. é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    print(f"\nğŸ“¤ é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {sending_results_csv}")
    
    if os.path.exists(sending_results_csv):
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰‹å‹•ã§èª­ã¿è¾¼ã¿ï¼ˆåˆ—æ•°ãŒä¸å®šã®ãŸã‚ï¼‰
            updated_rows = []
            with open(sending_results_csv, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                header = next(reader, None)
                if header:
                    updated_rows.append(header)
                
                for row in reader:
                    if len(row) > 0:
                        try:
                            old_id = int(row[0])
                            if old_id not in target_ids:
                                # IDã‚’æ–°ã—ã„å€¤ã«æ›´æ–°ï¼ˆç°¡å˜ã®ãŸã‚ã€å‰Šé™¤å¾Œã®é †åºã§å†æ¡ç•ªï¼‰
                                updated_rows.append(row)
                        except (ValueError, IndexError):
                            continue
            
            # æ›´æ–°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(sending_results_csv, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(updated_rows)
            
            print(f"âœ… é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {len(updated_rows)-1}è¡Œ")
            
        except Exception as e:
            print(f"âŒ é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"âš ï¸ {sending_results_csv} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 4. é€ä¿¡å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    print(f"\nğŸ“œ é€ä¿¡å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {sending_history_json}")
    
    if os.path.exists(sending_history_json):
        try:
            with open(sending_history_json, 'r', encoding='utf-8') as f:
                history_data = json.load(f)
            
            updated_history = {}
            for timestamp, entries in history_data.items():
                updated_entries = []
                for entry in entries:
                    if 'company_id' in entry:
                        old_id = entry['company_id']
                        if old_id not in target_ids:
                            updated_entries.append(entry)
                
                if updated_entries:
                    updated_history[timestamp] = updated_entries
            
            # æ›´æ–°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(sending_history_json, 'w', encoding='utf-8') as f:
                json.dump(updated_history, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… é€ä¿¡å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†")
            
        except Exception as e:
            print(f"âŒ é€ä¿¡å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"âš ï¸ {sending_history_json} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # å®Œäº†å ±å‘Š
    print(f"\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: data/new_input_test.csv_backup_20250627_150700")
    print(f"ğŸ“Š æœ€çµ‚ä¼æ¥­æ•°: {len(df_cleaned)}ç¤¾")
    print(f"ğŸ—‘ï¸ å‰Šé™¤ä¼æ¥­æ•°: {deleted_count}ç¤¾")
    print(f"ğŸ’¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªã—ã¦ãã ã•ã„: http://127.0.0.1:5002/companies")

if __name__ == "__main__":
    main()
