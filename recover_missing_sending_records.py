#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¬ è½ã—ãŸé€ä¿¡è¨˜éŒ²ã®å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

é«˜é€ŸåŒ–ã®ãŸã‚ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ãŸé€ä¿¡å±¥æ­´è¨˜éŒ²æ©Ÿèƒ½ã«ã‚ˆã‚Šã€
å®Ÿéš›ã«é€ä¿¡ã•ã‚ŒãŸãŒè¨˜éŒ²ã•ã‚Œãªã‹ã£ãŸé€ä¿¡å±¥æ­´ã‚’å¾©æ—§ã—ã¾ã™ã€‚
"""

import pandas as pd
import os
from datetime import datetime
import json

def recover_missing_sending_records():
    """æ¬ è½ã—ãŸé€ä¿¡è¨˜éŒ²ã‚’å¾©æ—§"""
    
    print("ğŸ”§ æ¬ è½ã—ãŸé€ä¿¡è¨˜éŒ²ã®å¾©æ—§ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 60)
    
    # ãƒã‚¦ãƒ³ã‚¹ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ç¢ºèªã•ã‚ŒãŸé€ä¿¡æƒ…å ±
    confirmed_sendings = [
        {
            'company_id': 1973,
            'company_name': 'å±±å´é‡‘å±ç”£æ¥­æ ªå¼ä¼šç¤¾',
            'email': 'info@yamakin.co.jp',
            'job_position': 'æ³•äººå–¶æ¥­',
            'send_time': '2025-06-26 11:07:18',
            'status': 'bounced',  # ãƒã‚¦ãƒ³ã‚¹ãƒ¡ãƒ¼ãƒ«ã§ç¢ºèª
            'bounce_reason': '550 5.4.1 Recipient address rejected: Access denied'
        }
    ]
    
    # æ¨å®šã•ã‚Œã‚‹é€ä¿¡ç¯„å›²ï¼ˆID 1971-1975ï¼‰ã®ä»–ã®ä¼æ¥­ã‚‚ç¢ºèª
    estimated_sendings = [
        {
            'company_id': 1971,
            'company_name': 'åŒ»ç™‚æ³•äººå¾³æ´²ä¼š',
            'email': 'info@yamauchi.or.jp',
            'job_position': 'è–¬å‰¤å¸«',
            'send_time': '2025-06-26 11:07:15',
            'status': 'sent'  # æ¨å®š
        },
        {
            'company_id': 1972,
            'company_name': 'å±±æœ¬åŸºç¤å·¥æ¥­æ ªå¼ä¼šç¤¾',
            'email': 'info@yamamotokiso.com',
            'job_position': 'æ²¹åœ§å›è·¯è¨­è¨ˆ',
            'send_time': '2025-06-26 11:07:16',
            'status': 'sent'  # æ¨å®š
        },
        {
            'company_id': 1974,
            'company_name': 'å±±ä¸€åŠ å·¥ç´™æ ªå¼ä¼šç¤¾',
            'email': 'info@yamaichi-k.co.jp',
            'job_position': 'æ³•äººå–¶æ¥­',
            'send_time': '2025-06-26 11:07:19',
            'status': 'sent'  # æ¨å®š
        },
        {
            'company_id': 1975,
            'company_name': 'æ ªå¼ä¼šç¤¾YAMAGIWA',
            'email': 'info@yamagiwa.co.jp',
            'job_position': 'æ³•äººå–¶æ¥­',
            'send_time': '2025-06-26 11:07:20',
            'status': 'sent'  # æ¨å®š
        }
    ]
    
    all_sendings = confirmed_sendings + estimated_sendings
    
    print(f"ğŸ“Š å¾©æ—§å¯¾è±¡ã®é€ä¿¡è¨˜éŒ²: {len(all_sendings)}ä»¶")
    print()
    
    # 1. å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆdata/new_input_test.csvï¼‰ã‚’æ›´æ–°
    update_original_csv_file(all_sendings)
    
    # 2. é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆhuganjob_email_resolution_results.csvï¼‰ã‚’æ›´æ–°
    update_resolution_results_file(all_sendings)
    
    # 3. å¾©æ—§ãƒ­ã‚°ã‚’è¨˜éŒ²
    create_recovery_log(all_sendings)
    
    print("\nğŸ‰ é€ä¿¡è¨˜éŒ²å¾©æ—§å®Œäº†")

def update_original_csv_file(sendings):
    """å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    
    print("1ï¸âƒ£ å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°")
    print("-" * 30)
    
    csv_file = 'data/new_input_test.csv'
    
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        updated_count = 0
        
        for sending in sendings:
            company_id = sending['company_id']
            email = sending['email']
            status = 'é€ä¿¡æ¸ˆã¿' if sending['status'] == 'sent' else 'ãƒã‚¦ãƒ³ã‚¹'
            send_time = sending['send_time']
            
            # è©²å½“ã™ã‚‹ä¼æ¥­IDã®è¡Œã‚’æ¤œç´¢
            mask = df['ID'] == company_id
            if mask.any():
                # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¨é€ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                df.loc[mask, 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = email
                df.loc[mask, 'é€ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = status
                df.loc[mask, 'é€ä¿¡æ—¥æ™‚'] = send_time
                
                if sending['status'] == 'bounced':
                    df.loc[mask, 'ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸'] = sending.get('bounce_reason', 'ãƒã‚¦ãƒ³ã‚¹')
                
                updated_count += 1
                print(f"  âœ… ID {company_id} ({sending['company_name']}) -> {status}")
            else:
                print(f"  âš ï¸ ID {company_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ“ å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {updated_count}ä»¶")
        
    except Exception as e:
        print(f"âŒ å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

def update_resolution_results_file(sendings):
    """é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    
    print("\n2ï¸âƒ£ é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°")
    print("-" * 30)
    
    results_file = 'huganjob_email_resolution_results.csv'
    
    try:
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        if os.path.exists(results_file):
            df = pd.read_csv(results_file, encoding='utf-8')
        else:
            df = pd.DataFrame()
        
        updated_count = 0
        
        for sending in sendings:
            company_id = sending['company_id']
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            mask = df['company_id'] == company_id
            if mask.any():
                # extraction_methodã‚’æ›´æ–°
                df.loc[mask, 'extraction_method'] = 'email_sending_recovered'
                df.loc[mask, 'status'] = 'recovered'
                updated_count += 1
                print(f"  âœ… ID {company_id} ã®æŠ½å‡ºæ–¹æ³•ã‚’æ›´æ–°")
            else:
                # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                new_data = {
                    'company_id': company_id,
                    'company_name': sending['company_name'],
                    'website': 'N/A',
                    'job_position': sending['job_position'],
                    'csv_email': sending['email'],
                    'final_email': sending['email'],
                    'extraction_method': 'email_sending_recovered',
                    'status': 'recovered'
                }
                
                new_df = pd.DataFrame([new_data])
                df = pd.concat([df, new_df], ignore_index=True)
                updated_count += 1
                print(f"  âœ… ID {company_id} ã®æ–°ã—ã„è¨˜éŒ²ã‚’è¿½åŠ ")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        df.to_csv(results_file, index=False, encoding='utf-8')
        print(f"\nğŸ“ é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {updated_count}ä»¶")
        
    except Exception as e:
        print(f"âŒ é€ä¿¡çµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

def create_recovery_log(sendings):
    """å¾©æ—§ãƒ­ã‚°ã‚’ä½œæˆ"""
    
    print("\n3ï¸âƒ£ å¾©æ—§ãƒ­ã‚°ä½œæˆ")
    print("-" * 30)
    
    try:
        recovery_log = {
            'recovery_time': datetime.now().isoformat(),
            'reason': 'é«˜é€ŸåŒ–ã®ãŸã‚ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ãŸé€ä¿¡å±¥æ­´è¨˜éŒ²æ©Ÿèƒ½ã«ã‚ˆã‚‹è¨˜éŒ²æ¬ è½',
            'evidence': 'ãƒã‚¦ãƒ³ã‚¹ãƒ¡ãƒ¼ãƒ«ï¼ˆID 1973 å±±å´é‡‘å±ç”£æ¥­æ ªå¼ä¼šç¤¾ï¼‰',
            'recovered_sendings': sendings,
            'total_recovered': len(sendings)
        }
        
        log_file = 'logs/sending_record_recovery.log'
        os.makedirs('logs', exist_ok=True)
        
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()}: {json.dumps(recovery_log, ensure_ascii=False, indent=2)}\n")
        
        print(f"ğŸ“ å¾©æ—§ãƒ­ã‚°ä½œæˆå®Œäº†: {log_file}")
        
    except Exception as e:
        print(f"âŒ å¾©æ—§ãƒ­ã‚°ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸš€ HUGANJOBã‚·ã‚¹ãƒ†ãƒ  é€ä¿¡è¨˜éŒ²å¾©æ—§ãƒ„ãƒ¼ãƒ«")
    print("   é«˜é€ŸåŒ–ã«ã‚ˆã‚Šæ¬ è½ã—ãŸé€ä¿¡å±¥æ­´ã‚’å¾©æ—§ã—ã¾ã™")
    print()
    
    recover_missing_sending_records()

if __name__ == "__main__":
    main()
