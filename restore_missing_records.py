#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€ä¿¡è¨˜éŒ²å¾©å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é€ä¿¡å±¥æ­´ã‹ã‚‰æ¬ è½ã—ãŸé€ä¿¡çµæœã‚’å¾©å…ƒã—ã€çµ±è¨ˆã‚’ä¿®æ­£
"""

import json
import csv
import pandas as pd
from datetime import datetime
import os
import shutil

def main():
    print("=" * 60)
    print("ğŸ”§ é€ä¿¡è¨˜éŒ²å¾©å…ƒå‡¦ç†é–‹å§‹")
    print("=" * 60)
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_file = f"new_email_sending_results_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    shutil.copy('new_email_sending_results.csv', backup_file)
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
    
    # é€ä¿¡å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
    try:
        with open('huganjob_sending_history.json', 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        print(f"ğŸ“‹ é€ä¿¡å±¥æ­´èª­ã¿è¾¼ã¿: {len(history['sending_records'])}ä»¶")
        
        # é€ä¿¡å±¥æ­´ã‚’ä¼æ¥­IDã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
        history_by_id = {}
        for record in history['sending_records']:
            try:
                company_id = int(record['company_id'])
                history_by_id[company_id] = record
            except:
                continue
        
        print(f"ğŸ“‹ é€ä¿¡å±¥æ­´ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¼æ¥­IDæ•°: {len(history_by_id)}ç¤¾")
        
    except Exception as e:
        print(f"âŒ é€ä¿¡å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # ç¾åœ¨ã®é€ä¿¡çµæœã‚’èª­ã¿è¾¼ã¿
    try:
        df_results = pd.read_csv('new_email_sending_results.csv', encoding='utf-8-sig')
        existing_ids = set(df_results['ä¼æ¥­ID'].tolist())
        print(f"ğŸ“‹ æ—¢å­˜é€ä¿¡çµæœ: {len(existing_ids)}ç¤¾")
        
    except Exception as e:
        print(f"âŒ é€ä¿¡çµæœèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿
    try:
        df_companies = pd.read_csv('data/new_input_test.csv', encoding='utf-8-sig')
        companies_by_id = {}
        for _, company in df_companies.iterrows():
            companies_by_id[company['ID']] = company
        
        print(f"ğŸ“‹ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {len(companies_by_id)}ç¤¾")
        
    except Exception as e:
        print(f"âŒ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # æ¬ è½ã—ãŸè¨˜éŒ²ã‚’ç‰¹å®š
    history_ids = set(history_by_id.keys())
    missing_ids = history_ids - existing_ids
    
    print(f"\nğŸ” æ¬ è½è¨˜éŒ²åˆ†æ:")
    print(f"   é€ä¿¡å±¥æ­´ã«ã‚ã‚‹ä¼æ¥­ID: {len(history_ids)}ç¤¾")
    print(f"   é€ä¿¡çµæœã«ã‚ã‚‹ä¼æ¥­ID: {len(existing_ids)}ç¤¾")
    print(f"   æ¬ è½ã—ã¦ã„ã‚‹ä¼æ¥­ID: {len(missing_ids)}ç¤¾")
    
    if not missing_ids:
        print("âœ… æ¬ è½è¨˜éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“")
        return True
    
    # æ¬ è½è¨˜éŒ²ã‚’å¾©å…ƒ
    print(f"\nğŸ”§ æ¬ è½è¨˜éŒ²å¾©å…ƒé–‹å§‹:")
    restored_records = []
    
    for company_id in sorted(missing_ids):
        if company_id in history_by_id and company_id in companies_by_id:
            history_record = history_by_id[company_id]
            company_record = companies_by_id[company_id]
            
            # é€ä¿¡çµæœãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
            restored_record = {
                'ä¼æ¥­ID': company_id,
                'ä¼æ¥­å': company_record['ä¼æ¥­å'],
                'æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': company_record.get('æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', ''),
                'å‹Ÿé›†è·ç¨®': company_record.get('å‹Ÿé›†è·ç¨®', ''),
                'é€ä¿¡æ—¥æ™‚': history_record['send_time'].replace('T', ' ').replace('Z', ''),
                'é€ä¿¡çµæœ': 'success',  # é€ä¿¡å±¥æ­´ã«ã‚ã‚‹ã¨ã„ã†ã“ã¨ã¯é€ä¿¡æˆåŠŸ
                'ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ID': history_record.get('tracking_id', ''),
                'é€ä¿¡ã‚¨ãƒ©ãƒ¼': ''
            }
            
            restored_records.append(restored_record)
    
    print(f"   å¾©å…ƒå¯¾è±¡è¨˜éŒ²æ•°: {len(restored_records)}ä»¶")
    
    if restored_records:
        # æ—¢å­˜ã®é€ä¿¡çµæœã¨å¾©å…ƒè¨˜éŒ²ã‚’çµåˆ
        df_restored = pd.DataFrame(restored_records)
        df_combined = pd.concat([df_results, df_restored], ignore_index=True)
        
        # ä¼æ¥­IDã§ã‚½ãƒ¼ãƒˆ
        df_combined = df_combined.sort_values('ä¼æ¥­ID')
        
        # å¾©å…ƒã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        restored_file = 'new_email_sending_results_restored.csv'
        df_combined.to_csv(restored_file, index=False, encoding='utf-8-sig')
        
        print(f"âœ… å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {restored_file}")
        print(f"   ç·è¨˜éŒ²æ•°: {len(df_combined)}ä»¶")
        print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¼æ¥­IDæ•°: {df_combined['ä¼æ¥­ID'].nunique()}ç¤¾")
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãæ›ãˆ
        shutil.copy(restored_file, 'new_email_sending_results.csv')
        print(f"âœ… ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†")
        
        # å¾©å…ƒã•ã‚ŒãŸè¨˜éŒ²ã®è©³ç´°è¡¨ç¤º
        print(f"\nğŸ“‹ å¾©å…ƒè¨˜éŒ²ã®è©³ç´°ï¼ˆæœ€åˆã®10ä»¶ï¼‰:")
        for record in restored_records[:10]:
            print(f"   ID {record['ä¼æ¥­ID']}: {record['ä¼æ¥­å']} - {record['é€ä¿¡æ—¥æ™‚']}")
        
        if len(restored_records) > 10:
            print(f"   ... ä»– {len(restored_records) - 10}ä»¶")
    
    # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
    print(f"\nğŸ“Š å¾©å…ƒå¾Œã®çµ±è¨ˆ:")
    df_final = pd.read_csv('new_email_sending_results.csv', encoding='utf-8-sig')
    
    total_records = len(df_final)
    unique_companies = df_final['ä¼æ¥­ID'].nunique()
    success_count = len(df_final[df_final['é€ä¿¡çµæœ'] == 'success'])
    
    print(f"   ç·é€ä¿¡è¨˜éŒ²æ•°: {total_records}ä»¶")
    print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¼æ¥­æ•°: {unique_companies}ç¤¾")
    print(f"   é€ä¿¡æˆåŠŸæ•°: {success_count}ä»¶")
    
    # é€ä¿¡çµæœã®å†…è¨³
    result_counts = df_final['é€ä¿¡çµæœ'].value_counts()
    print(f"\nğŸ“ˆ é€ä¿¡çµæœå†…è¨³:")
    for result, count in result_counts.items():
        print(f"   {result}: {count}ä»¶")
    
    # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®æ•´åˆæ€§ç¢ºèª
    total_companies = len(df_companies)
    coverage = (unique_companies / total_companies) * 100
    
    print(f"\nğŸ¯ ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ:")
    print(f"   ç·ä¼æ¥­æ•°: {total_companies}ç¤¾")
    print(f"   é€ä¿¡æ¸ˆã¿ä¼æ¥­æ•°: {unique_companies}ç¤¾")
    print(f"   ã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage:.2f}%")
    
    # é…ä¿¡åœæ­¢ä¼æ¥­ã‚’é™¤å¤–ã—ãŸå®Ÿè³ªçš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸
    try:
        unsubscribe_log_path = 'data/huganjob_unsubscribe_log.csv'
        unsubscribed_count = 0
        if os.path.exists(unsubscribe_log_path):
            df_unsubscribe = pd.read_csv(unsubscribe_log_path, encoding='utf-8-sig')
            unsubscribed_count = len(df_unsubscribe)
        
        effective_total = total_companies - unsubscribed_count
        effective_coverage = (unique_companies / effective_total) * 100
        
        print(f"   é…ä¿¡åœæ­¢ä¼æ¥­æ•°: {unsubscribed_count}ç¤¾")
        print(f"   å®Ÿè³ªå¯¾è±¡ä¼æ¥­æ•°: {effective_total}ç¤¾")
        print(f"   å®Ÿè³ªã‚«ãƒãƒ¬ãƒƒã‚¸: {effective_coverage:.2f}%")
        
    except Exception as e:
        print(f"   é…ä¿¡åœæ­¢ä¼æ¥­æ•°ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nâœ… é€ä¿¡è¨˜éŒ²å¾©å…ƒå‡¦ç†å®Œäº†")
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
