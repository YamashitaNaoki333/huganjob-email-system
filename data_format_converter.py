#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ãƒ‡ãƒ¼ã‚¿å½¢å¼å¤‰æ›ãƒ„ãƒ¼ãƒ«
æ§˜ã€…ãªå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’HUGAN JOBã‚·ã‚¹ãƒ†ãƒ ç”¨ã«å¤‰æ›
"""

import os
import csv
import pandas as pd
import json
from datetime import datetime
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataFormatConverter:
    def __init__(self):
        self.standard_columns = {
            'ID': 'ID',
            'ä¼æ¥­å': 'ä¼æ¥­å',
            'URL': 'URL',
            'æ¥­ç¨®': 'æ¥­ç¨®',
            'æ‰€åœ¨åœ°': 'æ‰€åœ¨åœ°',
            'å¾“æ¥­å“¡æ•°': 'å¾“æ¥­å“¡æ•°',
            'è³‡æœ¬é‡‘': 'è³‡æœ¬é‡‘',
            'å£²ä¸Šé«˜': 'å£²ä¸Šé«˜',
            'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'
        }
        
        # ã‚ˆãã‚ã‚‹ã‚«ãƒ©ãƒ åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.column_mappings = {
            # ä¼æ¥­åã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'ä¼šç¤¾å': 'ä¼æ¥­å',
            'æ³•äººå': 'ä¼æ¥­å',
            'äº‹å‹™æ‰€å': 'ä¼æ¥­å',
            'çµ„ç¹”å': 'ä¼æ¥­å',
            'company_name': 'ä¼æ¥­å',
            'Company Name': 'ä¼æ¥­å',
            
            # URLã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'ä¼æ¥­URL': 'URL',
            'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ': 'URL',
            'ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸': 'URL',
            'website': 'URL',
            'Website': 'URL',
            'url': 'URL',
            'HP': 'URL',
            
            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            'Email': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            'email': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            'E-mail': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            'mail': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            'Mail': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹',
            
            # æ¥­ç¨®ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'æ¥­ç•Œ': 'æ¥­ç¨®',
            'industry': 'æ¥­ç¨®',
            'Industry': 'æ¥­ç¨®',
            'äº‹æ¥­å†…å®¹': 'æ¥­ç¨®',
            
            # æ‰€åœ¨åœ°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'ä½æ‰€': 'æ‰€åœ¨åœ°',
            'æœ¬ç¤¾æ‰€åœ¨åœ°': 'æ‰€åœ¨åœ°',
            'æ‰€åœ¨åœ°ä½æ‰€': 'æ‰€åœ¨åœ°',
            'address': 'æ‰€åœ¨åœ°',
            'Address': 'æ‰€åœ¨åœ°',
            'location': 'æ‰€åœ¨åœ°',
            'Location': 'æ‰€åœ¨åœ°',
            
            # å¾“æ¥­å“¡æ•°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'ç¤¾å“¡æ•°': 'å¾“æ¥­å“¡æ•°',
            'äººæ•°': 'å¾“æ¥­å“¡æ•°',
            'employees': 'å¾“æ¥­å“¡æ•°',
            'Employees': 'å¾“æ¥­å“¡æ•°',
            'å¾“æ¥­å“¡': 'å¾“æ¥­å“¡æ•°',
            
            # è³‡æœ¬é‡‘ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'capital': 'è³‡æœ¬é‡‘',
            'Capital': 'è³‡æœ¬é‡‘',
            'è³‡æœ¬': 'è³‡æœ¬é‡‘',
            
            # å£²ä¸Šé«˜ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            'å£²ä¸Š': 'å£²ä¸Šé«˜',
            'revenue': 'å£²ä¸Šé«˜',
            'Revenue': 'å£²ä¸Šé«˜',
            'sales': 'å£²ä¸Šé«˜',
            'Sales': 'å£²ä¸Šé«˜'
        }
    
    def detect_format(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œå‡º"""
        _, ext = os.path.splitext(file_path)
        ext = ext.lower()
        
        if ext == '.csv':
            return 'csv'
        elif ext in ['.xlsx', '.xls']:
            return 'excel'
        elif ext == '.json':
            return 'json'
        elif ext == '.txt':
            return 'text'
        else:
            return 'unknown'
    
    def convert_csv_format(self, input_file, output_file=None):
        """CSVå½¢å¼ã®å¤‰æ›"""
        print(f"ğŸ“Š CSVå½¢å¼å¤‰æ›: {input_file}")
        print("-" * 50)
        
        # è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿è©¦è¡Œ
        encodings = ['utf-8-sig', 'utf-8', 'shift_jis', 'cp932', 'iso-2022-jp']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(input_file, encoding=encoding)
                print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ (ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding})")
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({encoding}): {e}")
                continue
        
        if df is None:
            print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        return self._standardize_dataframe(df, output_file)
    
    def convert_excel_format(self, input_file, output_file=None, sheet_name=0):
        """Excelå½¢å¼ã®å¤‰æ›"""
        print(f"ğŸ“Š Excelå½¢å¼å¤‰æ›: {input_file}")
        print("-" * 50)
        
        try:
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—
            excel_file = pd.ExcelFile(input_file)
            print(f"ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸã‚·ãƒ¼ãƒˆ: {excel_file.sheet_names}")
            
            # ã‚·ãƒ¼ãƒˆé¸æŠ
            if isinstance(sheet_name, int):
                if sheet_name < len(excel_file.sheet_names):
                    selected_sheet = excel_file.sheet_names[sheet_name]
                else:
                    selected_sheet = excel_file.sheet_names[0]
            else:
                selected_sheet = sheet_name if sheet_name in excel_file.sheet_names else excel_file.sheet_names[0]
            
            print(f"ğŸ“„ ä½¿ç”¨ã‚·ãƒ¼ãƒˆ: {selected_sheet}")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            df = pd.read_excel(input_file, sheet_name=selected_sheet)
            print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            
            return self._standardize_dataframe(df, output_file)
            
        except Exception as e:
            print(f"âŒ Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def convert_json_format(self, input_file, output_file=None):
        """JSONå½¢å¼ã®å¤‰æ›"""
        print(f"ğŸ“Š JSONå½¢å¼å¤‰æ›: {input_file}")
        print("-" * 50)
        
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # JSONã®æ§‹é€ ã‚’åˆ†æ
            if isinstance(data, list):
                # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                df = pd.DataFrame(data)
            elif isinstance(data, dict):
                # è¾æ›¸å½¢å¼ã®å ´åˆ
                if 'data' in data:
                    df = pd.DataFrame(data['data'])
                elif 'companies' in data:
                    df = pd.DataFrame(data['companies'])
                else:
                    # è¾æ›¸ã®å€¤ãŒãƒªã‚¹ãƒˆã®å ´åˆ
                    for key, value in data.items():
                        if isinstance(value, list):
                            df = pd.DataFrame(value)
                            break
                    else:
                        # å˜ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å ´åˆ
                        df = pd.DataFrame([data])
            else:
                print("âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„JSONæ§‹é€ ã§ã™")
                return None
            
            print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            
            return self._standardize_dataframe(df, output_file)
            
        except Exception as e:
            print(f"âŒ JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def convert_text_format(self, input_file, output_file=None, delimiter='\t'):
        """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å¤‰æ›"""
        print(f"ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼å¤‰æ›: {input_file}")
        print("-" * 50)
        
        # åŒºåˆ‡ã‚Šæ–‡å­—ã®è‡ªå‹•æ¤œå‡º
        delimiters = ['\t', ',', ';', '|']
        
        for delim in delimiters:
            try:
                df = pd.read_csv(input_file, delimiter=delim, encoding='utf-8')
                if len(df.columns) > 1:  # è¤‡æ•°åˆ—ã«åˆ†ã‹ã‚Œã¦ã„ã‚‹å ´åˆ
                    print(f"âœ… åŒºåˆ‡ã‚Šæ–‡å­—æ¤œå‡º: '{delim}'")
                    break
            except:
                continue
        else:
            print("âŒ é©åˆ‡ãªåŒºåˆ‡ã‚Šæ–‡å­—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
        
        return self._standardize_dataframe(df, output_file)
    
    def _standardize_dataframe(self, df, output_file=None):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¨™æº–å½¢å¼ã«å¤‰æ›"""
        print(f"\nğŸ”„ ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–å‡¦ç†")
        print("-" * 30)
        
        # å…ƒã®ã‚«ãƒ©ãƒ åã‚’è¡¨ç¤º
        print(f"ğŸ“‹ å…ƒã®ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
        # ã‚«ãƒ©ãƒ åã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        df_renamed = df.rename(columns=self.column_mappings)
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã‚’è¡¨ç¤º
        renamed_columns = {old: new for old, new in self.column_mappings.items() if old in df.columns}
        if renamed_columns:
            print(f"ğŸ”„ ã‚«ãƒ©ãƒ åå¤‰æ›´:")
            for old, new in renamed_columns.items():
                print(f"  {old} â†’ {new}")
        
        # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
        if 'ä¼æ¥­å' not in df_renamed.columns:
            # æœ€åˆã®ã‚«ãƒ©ãƒ ã‚’ä¼æ¥­åã¨ã—ã¦ä½¿ç”¨
            if len(df_renamed.columns) > 0:
                first_col = df_renamed.columns[0]
                df_renamed = df_renamed.rename(columns={first_col: 'ä¼æ¥­å'})
                print(f"ğŸ“ '{first_col}' ã‚’ 'ä¼æ¥­å' ã¨ã—ã¦ä½¿ç”¨")
        
        # URLã‚«ãƒ©ãƒ ã®å‡¦ç†
        if 'URL' not in df_renamed.columns:
            # URLå€™è£œã‚’æ¢ã™
            url_candidates = [col for col in df_renamed.columns 
                            if 'url' in col.lower() or 'http' in str(df_renamed[col].iloc[0] if len(df_renamed) > 0 else '').lower()]
            if url_candidates:
                df_renamed = df_renamed.rename(columns={url_candidates[0]: 'URL'})
                print(f"ğŸ“ '{url_candidates[0]}' ã‚’ 'URL' ã¨ã—ã¦ä½¿ç”¨")
            else:
                df_renamed['URL'] = ''
                print(f"ğŸ“ ç©ºã® 'URL' ã‚«ãƒ©ãƒ ã‚’ä½œæˆ")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        print(f"\nğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°:")
        
        # ç©ºè¡Œã®å‰Šé™¤
        original_len = len(df_renamed)
        df_renamed = df_renamed.dropna(how='all')
        if len(df_renamed) != original_len:
            print(f"  ç©ºè¡Œå‰Šé™¤: {original_len - len(df_renamed)}è¡Œ")
        
        # ä¼æ¥­åãŒç©ºã®è¡Œã‚’å‰Šé™¤
        if 'ä¼æ¥­å' in df_renamed.columns:
            original_len = len(df_renamed)
            df_renamed = df_renamed[df_renamed['ä¼æ¥­å'].notna() & (df_renamed['ä¼æ¥­å'] != '')]
            if len(df_renamed) != original_len:
                print(f"  ä¼æ¥­åç©ºç™½è¡Œå‰Šé™¤: {original_len - len(df_renamed)}è¡Œ")
        
        # URLã®æ­£è¦åŒ–
        if 'URL' in df_renamed.columns:
            df_renamed['URL'] = df_renamed['URL'].fillna('')
            df_renamed['URL'] = df_renamed['URL'].astype(str)
            
            # httpãŒå«ã¾ã‚Œã¦ã„ãªã„URLã«https://ã‚’è¿½åŠ 
            mask = (df_renamed['URL'] != '') & (~df_renamed['URL'].str.contains('http', na=False))
            df_renamed.loc[mask, 'URL'] = 'https://' + df_renamed.loc[mask, 'URL']
            print(f"  URLæ­£è¦åŒ–å®Œäº†")
        
        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ¤œè¨¼
        if 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹' in df_renamed.columns:
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
            valid_emails = df_renamed['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].str.match(email_pattern, na=False)
            invalid_count = (~valid_emails & df_renamed['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].notna()).sum()
            if invalid_count > 0:
                df_renamed.loc[~valid_emails, 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = ''
                print(f"  ç„¡åŠ¹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚¯ãƒªã‚¢: {invalid_count}ä»¶")
        
        # IDã‚«ãƒ©ãƒ ã®è¿½åŠ 
        df_renamed.insert(0, 'ID', range(1, len(df_renamed) + 1))
        
        # æ¨™æº–ã‚«ãƒ©ãƒ é †åºã«ä¸¦ã³æ›¿ãˆ
        available_columns = ['ID'] + [col for col in self.standard_columns.values() if col in df_renamed.columns and col != 'ID']
        other_columns = [col for col in df_renamed.columns if col not in available_columns]
        final_columns = available_columns + other_columns
        
        df_final = df_renamed[final_columns]
        
        print(f"âœ… æ¨™æº–åŒ–å®Œäº†: {len(df_final)}è¡Œ Ã— {len(df_final.columns)}åˆ—")
        print(f"ğŸ“‹ æœ€çµ‚ã‚«ãƒ©ãƒ : {list(df_final.columns)}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        if output_file:
            try:
                df_final.to_csv(output_file, index=False, encoding='utf-8-sig')
                print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return df_final
    
    def interactive_conversion(self):
        """å¯¾è©±å¼å¤‰æ›"""
        print("=" * 80)
        print("ğŸ”„ HUGAN JOB ãƒ‡ãƒ¼ã‚¿å½¢å¼å¤‰æ›ãƒ„ãƒ¼ãƒ«")
        print("=" * 80)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
        print("\nğŸ“ å¤‰æ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
        input_file = input("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: ").strip().strip('"')
        
        if not input_file or not os.path.exists(input_file):
            print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # å½¢å¼æ¤œå‡º
        file_format = self.detect_format(input_file)
        print(f"ğŸ“Š æ¤œå‡ºã•ã‚ŒãŸå½¢å¼: {file_format}")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        print(f"\nğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ç©ºç™½ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ):")
        output_file = input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å: ").strip()
        if not output_file:
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            output_file = f"{base_name}_converted.csv"
        
        # å¤‰æ›å®Ÿè¡Œ
        try:
            if file_format == 'csv':
                result = self.convert_csv_format(input_file, output_file)
            elif file_format == 'excel':
                result = self.convert_excel_format(input_file, output_file)
            elif file_format == 'json':
                result = self.convert_json_format(input_file, output_file)
            elif file_format == 'text':
                result = self.convert_text_format(input_file, output_file)
            else:
                print(f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼: {file_format}")
                return False
            
            if result is not None:
                print(f"\nğŸ‰ å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
                print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(result)}ä»¶")
                
                # çµ±è¨ˆæƒ…å ±
                print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
                if 'ä¼æ¥­å' in result.columns:
                    print(f"  ä¼æ¥­å: {result['ä¼æ¥­å'].notna().sum()}ä»¶")
                if 'URL' in result.columns:
                    valid_urls = result['URL'].str.contains('http', na=False).sum()
                    print(f"  æœ‰åŠ¹URL: {valid_urls}ä»¶")
                if 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹' in result.columns:
                    valid_emails = result['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].notna().sum()
                    print(f"  ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: {valid_emails}ä»¶")
                
                return True
            else:
                print(f"âŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except Exception as e:
            print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    converter = DataFormatConverter()
    
    try:
        success = converter.interactive_conversion()
        if success:
            print(f"\nâœ… å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        else:
            print(f"\nâŒ å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ")
    except KeyboardInterrupt:
        print(f"\n\nâŒ å‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
