#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HUGAN JOB ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯
CSVã®æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã‚’å„ªå…ˆã—ã€ç©ºç™½ã®å ´åˆã¯ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚’å®Ÿè¡Œ

ä½œæˆæ—¥æ™‚: 2025å¹´06æœˆ20æ—¥ 22:00:00
ä½œæˆè€…: AI Assistant
"""

import pandas as pd
import re
import logging
import sys
import os
import time
from pathlib import Path
from urllib.parse import urljoin, urlparse

# ãƒ­ã‚°è¨­å®šï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚INFOãƒ¬ãƒ™ãƒ«ã«è¨­å®šï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/huganjob_email_resolver.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# é«˜é€ŸåŒ–ã®ãŸã‚ã€è©³ç´°ãƒ­ã‚°ã‚’ç„¡åŠ¹åŒ–
logging.getLogger('requests').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)

class HuganJobEmailResolver:
    """HUGAN JOB ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, csv_file_path="data/new_input_test.csv"):
        """
        åˆæœŸåŒ–
        
        Args:
            csv_file_path (str): ä¼æ¥­ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.csv_file_path = csv_file_path
        self.companies_df = None
        self.email_results = []
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs('logs', exist_ok=True)
        
    def load_companies_data(self):
        """ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            logger.info(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {self.csv_file_path}")
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(self.csv_file_path):
                raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_file_path}")
            
            # CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            self.companies_df = pd.read_csv(self.csv_file_path, encoding='utf-8')
            
            # åˆ—åã®ç¢ºèªã¨æ­£è¦åŒ–
            expected_columns = ['ID', 'ä¼æ¥­å', 'ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸', 'æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'å‹Ÿé›†è·ç¨®']
            if list(self.companies_df.columns) != expected_columns:
                logger.warning(f"åˆ—åãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {list(self.companies_df.columns)}")
                logger.info(f"æœŸå¾…å€¤: {expected_columns}")
            
            logger.info(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.companies_df)}ç¤¾")
            return True
            
        except Exception as e:
            logger.error(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def is_valid_email(self, email):
        """
        ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åç­‰ã®é™¤å¤–ã‚’å«ã‚€ï¼‰

        Args:
            email (str): ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹

        Returns:
            bool: æœ‰åŠ¹ãªå ´åˆTrue
        """
        if pd.isna(email) or email in ['â€', '-', '', ' ', None]:
            return False

        email_str = str(email).strip()
        if not email_str:
            return False

        # åŸºæœ¬çš„ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å½¢å¼ãƒã‚§ãƒƒã‚¯
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(email_pattern, email_str):
            return False

        # é•·ã•ãƒã‚§ãƒƒã‚¯
        if len(email_str) > 254:  # RFC 5321ã®åˆ¶é™
            return False

        # ãƒ­ãƒ¼ã‚«ãƒ«éƒ¨ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³éƒ¨ã®åˆ†é›¢
        try:
            local_part, domain_part = email_str.split('@', 1)
            if len(local_part) > 64 or len(local_part) == 0:  # RFC 5321ã®åˆ¶é™
                return False
            if len(domain_part) == 0:
                return False
        except ValueError:
            return False

        # ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®é™¤å¤–ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§å¹…æ‹¡å¼µï¼‰
        invalid_extensions = {
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            '.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.bmp', '.ico',
            '.tiff', '.tif', '.avif', '.heic', '.heif',
            # ã‚¦ã‚§ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«
            '.css', '.js', '.woff', '.woff2', '.otf', '.ttf', '.eot',
            '.map', '.json', '.xml', '.html', '.htm',
            # ç„¡åŠ¹ãªãƒ‰ãƒ¡ã‚¤ãƒ³æ‹¡å¼µå­
            '.print', '.catalog', '.shop', '.contact', '.nav', '.main',
            '.logo', '.banner', '.header', '.footer', '.sidebar', '.content',
            '.image', '.string', '.easing', '.name', '.version', '.params',
            '.config', '.settings', '.options', '.plugin', '.custom',
            '.retargeting', '.datalayer', '.large', '.term', '.jquery',
            # JavaScript/CSSé–¢é€£
            '.init', '.top', '.bottom', '.post', '.postdata', '.combox',
            '.duration', '.after', '.selector', '.offset', '.areas',
            '.mode', '.me', '.tag', '.captcha', '.mp', '.bg', '.com'
        }

        # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å¤–ãƒã‚§ãƒƒã‚¯ï¼ˆ@2x.png, @3x.jpgç­‰ï¼‰
        responsive_patterns = [
            r'@\d+x\.(jpg|jpeg|png|gif|svg|webp|bmp|ico)$',
            r'@retina\.(jpg|jpeg|png|gif|svg|webp|bmp|ico)$',
            r'@mobile\.(jpg|jpeg|png|gif|svg|webp|bmp|ico)$',
            r'@tablet\.(jpg|jpeg|png|gif|svg|webp|bmp|ico)$'
        ]

        email_lower = email_str.lower()

        # ç„¡åŠ¹ãªæ‹¡å¼µå­ã®äº‹å‰ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€ŸåŒ–ï¼‰
        if any(email_lower.endswith(ext) for ext in invalid_extensions):
            return False

        # ãƒ‰ãƒ¡ã‚¤ãƒ³éƒ¨ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        if not domain_part or '.' not in domain_part:
            return False

        # æœ‰åŠ¹ãªTLDãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
        domain_parts = domain_part.split('.')
        if len(domain_parts) < 2:
            return False

        # æœ€å¾Œã®éƒ¨åˆ†ï¼ˆTLDï¼‰ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
        tld = domain_parts[-1]
        if len(tld) < 2 or not tld.isalpha():
            return False

        # é€£ç¶šã™ã‚‹ãƒ‰ãƒƒãƒˆã‚„ç„¡åŠ¹ãªæ–‡å­—ã®ãƒã‚§ãƒƒã‚¯
        if '..' in email_str or email_str.startswith('.') or email_str.endswith('.'):
            return False

        # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern in responsive_patterns:
            if re.search(pattern, email_lower):
                return False

        # ä¸€èˆ¬çš„ãªç„¡åŠ¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å¤–
        invalid_patterns = [
            r'@\d+x\d+\.',  # @1080x360.jpgç­‰ã®ã‚µã‚¤ã‚ºæŒ‡å®š
            r'@sp\.',       # @sp.jpgç­‰ã®ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ç”¨
            r'@pc\.',       # @pc.jpgç­‰ã®PCç”¨
            r'@mobile\.',   # @mobile.jpgç­‰
            r'@tablet\.',   # @tablet.jpgç­‰
            r'banner.*@.*\.(jpg|png|gif|svg)',  # ãƒãƒŠãƒ¼ç”»åƒ
            r'logo.*@.*\.(jpg|png|gif|svg)',    # ãƒ­ã‚´ç”»åƒ
            r'icon.*@.*\.(jpg|png|gif|svg)',    # ã‚¢ã‚¤ã‚³ãƒ³ç”»åƒ
            r'hero.*@.*\.(jpg|png|gif|svg)',    # ãƒ’ãƒ¼ãƒ­ãƒ¼ç”»åƒ
            r'thumb.*@.*\.(jpg|png|gif|svg)',   # ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒ
        ]

        for pattern in invalid_patterns:
            if re.search(pattern, email_lower):
                return False

        # é«˜é€Ÿãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼šJavaScript/CSSå¤‰æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å¤–
        invalid_patterns = [
            'window.', '.prototype.', '.version', '.params', '.config', '.settings', '.options',
            '@plugin.', '@custom.', '@retargeting.', '@datalayer.', '@large.', '@term.', '@jquery.',
            'summary@', 'search@', 'my@', 'gtm4wp@', '@reset.', '@polisy.', '@bg.', '@scroll.',
            '@fade.', '@hide.', '@element.', '@container.', '@widget.', '@reload.', '@check.',
            '@unit.', '@post.', '@challenge.', '@captcha.', '@2.', '@sp.', '@pc.', '@mobile.',
            '@tablet.', 'comp-', 'webpackjsonp', 'self.webpackjsonp', 'thunderbolt.app'
        ]

        # é«˜é€Ÿæ–‡å­—åˆ—æ¤œç´¢ï¼ˆæ­£è¦è¡¨ç¾ã‚ˆã‚Šé«˜é€Ÿï¼‰
        if any(pattern in email_lower for pattern in invalid_patterns):
            return False

        return True
    
    def extract_email_from_website(self, company_id, company_name, website_url):
        """
        ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŠ½å‡ºï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨ï¼‰

        Args:
            company_id (int): ä¼æ¥­ID
            company_name (str): ä¼æ¥­å
            website_url (str): ä¼æ¥­ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆURL

        Returns:
            str or None: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            # æ—¢å­˜ã®ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            extraction_files = [
                'new_email_extraction_results_latest.csv',
                'huganjob_email_extraction_results.csv',
                'derivative_ad_email_extraction_results.csv'
            ]

            for extraction_file in extraction_files:
                if os.path.exists(extraction_file):
                    try:
                        extraction_df = pd.read_csv(extraction_file, encoding='utf-8')

                        # ä¼æ¥­IDã¾ãŸã¯ä¼æ¥­åã§æ¤œç´¢
                        if 'ä¼æ¥­ID' in extraction_df.columns:
                            match = extraction_df[extraction_df['ä¼æ¥­ID'] == company_id]
                        elif 'ID' in extraction_df.columns:
                            match = extraction_df[extraction_df['ID'] == company_id]
                        else:
                            # ä¼æ¥­åã§æ¤œç´¢
                            match = extraction_df[extraction_df['ä¼æ¥­å'] == company_name]

                        if not match.empty:
                            email_col = None
                            for col in ['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'email', 'Email', 'EMAIL']:
                                if col in match.columns:
                                    email_col = col
                                    break

                            if email_col:
                                extracted_email = match.iloc[0][email_col]
                                if self.is_valid_email(extracted_email):
                                    logger.info(f"æ—¢å­˜æŠ½å‡ºçµæœã‹ã‚‰å–å¾—: {company_name} -> {extracted_email}")
                                    return extracted_email.strip()

                    except Exception as e:
                        logger.warning(f"æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {extraction_file} - {e}")
                        continue

            # æ—¢å­˜ã®æŠ½å‡ºçµæœãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€æ–°è¦æŠ½å‡ºã‚’å®Ÿè¡Œ
            logger.info(f"æ–°è¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºå®Ÿè¡Œ: {company_name} ({website_url})")
            return self.run_email_extraction(company_id, company_name, website_url)

        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {company_name} - {e}")
            return None

    def run_email_extraction(self, company_id, company_name, website_url):
        """
        æ–°è¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚’å®Ÿè¡Œï¼ˆæ—¢å­˜ã®é«˜åº¦ãªã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨ï¼‰

        Args:
            company_id (int): ä¼æ¥­ID
            company_name (str): ä¼æ¥­å
            website_url (str): ä¼æ¥­ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆURL

        Returns:
            str or None: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            logger.info(f"ğŸ” é«˜åº¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºé–‹å§‹: {company_name}")

            # æ—¢å­˜ã®é«˜åº¦ãªãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            extracted_email = self.advanced_email_extraction(company_id, company_name, website_url)
            if extracted_email:
                logger.info(f"âœ… é«˜åº¦æŠ½å‡ºæˆåŠŸ: {company_name} -> {extracted_email}")
                return extracted_email

            # é«˜åº¦æŠ½å‡ºãŒå¤±æ•—ã—ãŸå ´åˆã¯ç°¡æ˜“æŠ½å‡ºã‚’å®Ÿè¡Œ
            logger.info(f"ğŸŒ ç°¡æ˜“æŠ½å‡ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {company_name}")
            return self.simple_email_extraction(website_url, company_name)

        except Exception as e:
            logger.error(f"æ–°è¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {company_name} - {e}")
            return None

    def advanced_email_extraction(self, company_id, company_name, website_url):
        """
        æ—¢å­˜ã®é«˜åº¦ãªãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨

        Args:
            company_id (int): ä¼æ¥­ID
            company_name (str): ä¼æ¥­å
            website_url (str): ä¼æ¥­ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆURL

        Returns:
            str or None: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            # æ—¢å­˜ã®é«˜åº¦ãªãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import sys
            import os

            # core_scriptsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
            core_scripts_path = os.path.join(os.getcwd(), 'core_scripts')
            if core_scripts_path not in sys.path:
                sys.path.append(core_scripts_path)

            from derivative_email_extractor import PrioritizedEmailExtractor

            # é«˜åº¦ãªãƒ¡ãƒ¼ãƒ«æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ï¼ˆé«˜é€Ÿè¨­å®šï¼‰
            extractor = PrioritizedEmailExtractor(
                timeout=5,
                max_retries=1,
                use_dynamic_extraction=False,  # é«˜é€ŸåŒ–ã®ãŸã‚ç„¡åŠ¹
                use_contact_form_analysis=False  # é«˜é€ŸåŒ–ã®ãŸã‚ç„¡åŠ¹
            )

            # å„ªå…ˆé †ä½ã«åŸºã¥ããƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚’å®Ÿè¡Œ
            result = extractor.extract_emails_with_priority(
                company_name=company_name,
                url=website_url,
                company_id=company_id
            )

            # æœ€é©ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—
            if result and result.get('best_email'):
                best_email = result['best_email']
                email_address = best_email.get('email')
                confidence = best_email.get('confidence', 0.0)
                source = best_email.get('source', 'unknown')

                logger.info(f"é«˜åº¦æŠ½å‡ºçµæœ: {company_name} -> {email_address} (ä¿¡é ¼åº¦: {confidence:.2f}, ã‚½ãƒ¼ã‚¹: {source})")

                # ä¿¡é ¼åº¦ãŒ0.3ä»¥ä¸Šã‹ã¤æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®å ´åˆã®ã¿æ¡ç”¨
                if confidence >= 0.3 and self.is_valid_email(email_address):
                    logger.info(f"âœ… é«˜åº¦æŠ½å‡ºæˆåŠŸ: {company_name} -> {email_address} (ä¿¡é ¼åº¦: {confidence:.2f})")
                    return email_address
                else:
                    if confidence < 0.3:
                        logger.warning(f"âŒ ä¿¡é ¼åº¦ãŒä½ã„ãŸã‚é™¤å¤–: {email_address} (ä¿¡é ¼åº¦: {confidence:.2f})")
                    else:
                        logger.warning(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åç­‰ã®ãŸã‚é™¤å¤–: {email_address}")

            # æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒãªã„å ´åˆ
            logger.info(f"é«˜åº¦æŠ½å‡ºã§ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {company_name}")
            return None

        except ImportError as e:
            logger.warning(f"é«˜åº¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
            return None
        except Exception as e:
            logger.error(f"é«˜åº¦ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {company_name} - {e}")
            return None

    def parse_extraction_result(self, company_id, company_name):
        """
        æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€æ–°ã®çµæœã‚’å–å¾—

        Args:
            company_id (int): ä¼æ¥­ID
            company_name (str): ä¼æ¥­å

        Returns:
            str or None: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
        """
        try:
            # æœ€æ–°ã®æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            result_files = [
                'email_extraction_results.csv',
                'derivative_ad_email_extraction_results.csv',
                'huganjob_email_extraction_results.csv'
            ]

            for result_file in result_files:
                if os.path.exists(result_file):
                    try:
                        df = pd.read_csv(result_file, encoding='utf-8')

                        # ä¼æ¥­IDã¾ãŸã¯ä¼æ¥­åã§æ¤œç´¢
                        if 'ID' in df.columns:
                            match = df[df['ID'] == company_id]
                        elif 'ä¼æ¥­ID' in df.columns:
                            match = df[df['ä¼æ¥­ID'] == company_id]
                        else:
                            match = df[df['ä¼æ¥­å'] == company_name]

                        if not match.empty:
                            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã‚’æ¢ã™
                            email_cols = ['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'email', 'Email', 'EMAIL', 'extracted_email']
                            for col in email_cols:
                                if col in match.columns:
                                    email = match.iloc[-1][col]  # æœ€æ–°ã®çµæœã‚’å–å¾—
                                    if self.is_valid_email(email):
                                        return str(email).strip()

                    except Exception as e:
                        logger.warning(f"çµæœãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {result_file} - {e}")
                        continue

            return None

        except Exception as e:
            logger.error(f"æŠ½å‡ºçµæœè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def simple_email_extraction(self, website_url, company_name):
        """
        ç°¡æ˜“ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºï¼ˆã‚¦ã‚§ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰

        Args:
            website_url (str): ä¼æ¥­ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆURL
            company_name (str): ä¼æ¥­å

        Returns:
            str or None: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
        """
        try:
            import requests

            logger.info(f"ğŸŒ ç°¡æ˜“ãƒ¡ãƒ¼ãƒ«æŠ½å‡º: {company_name} ({website_url})")

            # ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            response = requests.get(website_url, headers=headers, timeout=10)
            response.raise_for_status()

            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆæœ‰åŠ¹ãªTLDã®ã¿ï¼‰
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,6}\b'
            potential_emails = re.findall(email_pattern, response.text)

            # äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼šæ˜ã‚‰ã‹ã«ç„¡åŠ¹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
            invalid_extensions = {
                '.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.bmp', '.ico',
                '.css', '.js', '.html', '.htm', '.xml', '.json', '.pdf',
                '.print', '.catalog', '.shop', '.contact', '.nav', '.main',
                '.logo', '.banner', '.header', '.footer', '.sidebar', '.content'
            }

            # é«˜é€Ÿäº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_emails = []
            for email in potential_emails:
                email_lower = email.lower()
                if not any(email_lower.endswith(ext) for ext in invalid_extensions):
                    filtered_emails.append(email)

            # æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            valid_emails = []
            for email in filtered_emails:
                if self.is_valid_email(email):
                    # ä¸€èˆ¬çš„ã§ãªã„ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å„ªå…ˆ
                    if not any(generic in email.lower() for generic in ['noreply', 'no-reply', 'donotreply', 'example', 'test']):
                        valid_emails.append(email)
                        logger.info(f"âœ… ç°¡æ˜“æŠ½å‡ºã§æœ‰åŠ¹ãƒ¡ãƒ¼ãƒ«ç™ºè¦‹: {email}")
                    else:
                        logger.debug(f"âŒ ä¸€èˆ¬çš„ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãŸã‚é™¤å¤–: {email}")
                else:
                    logger.debug(f"âŒ ç„¡åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãŸã‚é™¤å¤–: {email}")

            if valid_emails:
                # æœ€åˆã®æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¿”ã™
                selected_email = valid_emails[0]
                logger.info(f"âœ… ç°¡æ˜“æŠ½å‡ºæˆåŠŸ: {company_name} -> {selected_email}")
                return selected_email
            else:
                logger.warning(f"âŒ ç°¡æ˜“æŠ½å‡ºå¤±æ•—: {company_name} (æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—)")
                return None

        except Exception as e:
            logger.warning(f"âŒ ç°¡æ˜“æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {company_name} - {e}")
            return None
    
    def resolve_email_addresses(self):
        """
        å…¨ä¼æ¥­ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æ±ºå®š
        
        Returns:
            list: ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šçµæœã®ãƒªã‚¹ãƒˆ
        """
        if self.companies_df is None:
            logger.error("ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        logger.info("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šå‡¦ç†é–‹å§‹")
        self.email_results = []
        
        for index, row in self.companies_df.iterrows():
            company_id = row['ID']
            company_name = row['ä¼æ¥­å']
            website_url = row['ä¼æ¥­ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸']
            csv_email = row['æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
            job_position = row['å‹Ÿé›†è·ç¨®']
            
            result = {
                'company_id': company_id,
                'company_name': company_name,
                'website_url': website_url,
                'job_position': job_position,
                'csv_email': csv_email,
                'final_email': None,
                'email_source': None,
                'status': 'pending'
            }
            
            # ç¬¬1å„ªå…ˆ: CSVã®æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
            if self.is_valid_email(csv_email):
                result['final_email'] = csv_email.strip()
                result['email_source'] = 'csv_direct'
                result['status'] = 'success'
                logger.info(f"âœ… CSVç›´æ¥: {company_name} -> {result['final_email']}")
            
            # ç¬¬2å„ªå…ˆ: ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ã®æŠ½å‡º
            else:
                extracted_email = self.extract_email_from_website(
                    company_id, company_name, website_url
                )
                
                if extracted_email and self.is_valid_email(extracted_email):
                    result['final_email'] = extracted_email.strip()
                    result['email_source'] = 'website_extraction'
                    result['status'] = 'success'
                    logger.info(f"âœ… æŠ½å‡ºæˆåŠŸ: {company_name} -> {result['final_email']}")
                else:
                    result['status'] = 'failed'
                    logger.warning(f"âŒ ãƒ¡ãƒ¼ãƒ«å–å¾—å¤±æ•—: {company_name}")
            
            self.email_results.append(result)
        
        # çµ±è¨ˆæƒ…å ±
        success_count = len([r for r in self.email_results if r['status'] == 'success'])
        csv_direct_count = len([r for r in self.email_results if r['email_source'] == 'csv_direct'])
        extraction_count = len([r for r in self.email_results if r['email_source'] == 'website_extraction'])
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šçµæœçµ±è¨ˆ")
        logger.info("=" * 60)
        logger.info(f"ç·ä¼æ¥­æ•°: {len(self.email_results)}")
        logger.info(f"æˆåŠŸ: {success_count} ({success_count/len(self.email_results)*100:.1f}%)")
        logger.info(f"  - CSVç›´æ¥: {csv_direct_count}")
        logger.info(f"  - ã‚¦ã‚§ãƒ–æŠ½å‡º: {extraction_count}")
        logger.info(f"å¤±æ•—: {len(self.email_results) - success_count}")
        logger.info("=" * 60)
        
        return self.email_results
    
    def get_sendable_companies(self):
        """
        é€ä¿¡å¯èƒ½ãªä¼æ¥­ãƒªã‚¹ãƒˆã‚’å–å¾—
        
        Returns:
            list: é€ä¿¡å¯èƒ½ãªä¼æ¥­ã®æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        if not self.email_results:
            logger.warning("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šå‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        sendable = [r for r in self.email_results if r['status'] == 'success']
        logger.info(f"é€ä¿¡å¯èƒ½ä¼æ¥­æ•°: {len(sendable)}")
        
        return sendable
    
    def save_results_to_csv(self, output_file="huganjob_email_resolution_results.csv"):
        """
        çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæ—¢å­˜çµæœã‚’ä¿æŒã—ãªãŒã‚‰è¿½åŠ ï¼‰

        Args:
            output_file (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        if not self.email_results:
            logger.warning("ä¿å­˜ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return False

        try:
            # æ–°ã—ã„çµæœã‚’DataFrameã«å¤‰æ›
            new_results_df = pd.DataFrame(self.email_results)

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿
            if os.path.exists(output_file):
                try:
                    existing_df = pd.read_csv(output_file, encoding='utf-8')
                    logger.info(f"æ—¢å­˜ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿: {len(existing_df)}è¡Œ")

                    # æ—¢å­˜ã®ä¼æ¥­IDã‚’å–å¾—
                    existing_ids = set(existing_df['company_id'].tolist()) if 'company_id' in existing_df.columns else set()

                    # æ–°ã—ã„çµæœã‹ã‚‰æ—¢å­˜IDã¨é‡è¤‡ã—ãªã„ã‚‚ã®ã®ã¿ã‚’æŠ½å‡º
                    new_ids = set(new_results_df['company_id'].tolist())
                    duplicate_ids = existing_ids.intersection(new_ids)

                    if duplicate_ids:
                        logger.info(f"é‡è¤‡ã™ã‚‹ä¼æ¥­ID: {sorted(duplicate_ids)}")
                        # é‡è¤‡ã™ã‚‹IDã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                        existing_df = existing_df[~existing_df['company_id'].isin(duplicate_ids)]
                        logger.info(f"é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤å¾Œ: {len(existing_df)}è¡Œ")

                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                    combined_df = pd.concat([existing_df, new_results_df], ignore_index=True)

                except Exception as e:
                    logger.warning(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}ã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™")
                    combined_df = new_results_df
            else:
                logger.info("æ–°ã—ã„çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ")
                combined_df = new_results_df

            # ä¼æ¥­IDã§ã‚½ãƒ¼ãƒˆ
            combined_df = combined_df.sort_values('company_id')

            # CSVã«ä¿å­˜
            combined_df.to_csv(output_file, index=False, encoding='utf-8')
            logger.info(f"çµæœã‚’CSVã«ä¿å­˜: {output_file} (åˆè¨ˆ: {len(combined_df)}è¡Œ)")
            return True

        except Exception as e:
            logger.error(f"CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(description='HUGAN JOB ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('--start-id', type=int, help='é–‹å§‹IDï¼ˆæŒ‡å®šã—ãŸå ´åˆã€ç¯„å›²å‡¦ç†ï¼‰')
    parser.add_argument('--end-id', type=int, help='çµ‚äº†IDï¼ˆæŒ‡å®šã—ãŸå ´åˆã€ç¯„å›²å‡¦ç†ï¼‰')
    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ“§ HUGAN JOB ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)

    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šå‡¦ç†
    resolver = HuganJobEmailResolver()

    # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not resolver.load_companies_data():
        print("âŒ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    # IDç¯„å›²æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if args.start_id is not None and args.end_id is not None:
        print(f"ğŸ¯ IDç¯„å›²æŒ‡å®š: {args.start_id} ï½ {args.end_id}")
        original_count = len(resolver.companies_df)
        resolver.companies_df = resolver.companies_df[
            (resolver.companies_df['ID'] >= args.start_id) &
            (resolver.companies_df['ID'] <= args.end_id)
        ]
        filtered_count = len(resolver.companies_df)
        print(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ: {original_count}ç¤¾ â†’ {filtered_count}ç¤¾")

        if filtered_count == 0:
            print("âŒ æŒ‡å®šã•ã‚ŒãŸIDç¯„å›²ã«è©²å½“ã™ã‚‹ä¼æ¥­ãŒã‚ã‚Šã¾ã›ã‚“")
            return False

    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®š
    results = resolver.resolve_email_addresses()

    if not results:
        print("âŒ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ±ºå®šå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    # çµæœä¿å­˜
    resolver.save_results_to_csv()

    # é€ä¿¡å¯èƒ½ä¼æ¥­ã®è¡¨ç¤º
    sendable = resolver.get_sendable_companies()

    print("\nğŸ“‹ é€ä¿¡å¯èƒ½ä¼æ¥­ï¼ˆæœ€åˆã®10ç¤¾ï¼‰:")
    for i, company in enumerate(sendable[:10]):
        print(f"  {i+1:2d}. {company['company_name']} -> {company['final_email']}")

    if len(sendable) > 10:
        print(f"  ... ä»– {len(sendable) - 10} ç¤¾")

    print(f"\nâœ… å‡¦ç†å®Œäº†: {len(sendable)} ç¤¾ãŒé€ä¿¡å¯èƒ½ã§ã™")
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâŒ å‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
